{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf20c5be-ad55-4ecd-86e4-0b06a3f6308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalMaxPool2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from numpy.linalg import norm\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13859217-282c-4036-a2f9-d324cd0aefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title('Fashion Recommender system')\n",
    "\n",
    "############################ Defining Model##############################################\n",
    "model=ResNet50(weights='imagenet',include_top=False, input_shape=(224,224,3))\n",
    "model.trainable=False\n",
    "model=tf.keras.Sequential([model,GlobalMaxPool2D()])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013ad11-d543-4037-8dbb-59cce3426521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(path,model):\n",
    "    img=image.load_img(path, target_size=(224,224))\n",
    "    img_arr=image.img_to_array(img)\n",
    "    ex_img_arr=np.expand_dims(img_arr,axis=0)#to make it compatible with the model input shape.\n",
    "    pre_pr_img=preprocess_input(ex_img_arr)#function that normalizes the pixel values\n",
    "\n",
    "    #Passes the image through the mode\n",
    "    result=model.predict(pre_pr_img).flatten() #Converts the multidimensional feature map into a 1D vector\n",
    "    #Normalize the Feature Vector\n",
    "    normal_result=result/norm(result) #Divides each element of the vector by its norm\n",
    "    return normal_result #Return the Feature Vector\n",
    "path=r'C:\\Users\\User\\Desktop\\archive2\\images' #images file\n",
    "# Combines the directory path and file name to create the full file path for each image.\n",
    "images=[os.path.join(path,files) for files in os.listdir(path)]\n",
    "# Saving Image Paths to a File (images.pkl)\n",
    "pickle.dump(images,open('images.pkl','wb'))\n",
    "# Extracting Features from Images\n",
    "feature_list=[] #A list that will store the feature vectors for each image\n",
    "for file in tqdm(images): #Adds a progress bar to the loop to show the processing status\n",
    "    feature_list.append(image_preprocess(file, model)) #Read image file and Preprocesses the image to match the input format \n",
    "    #Passes the image through the model to extract features\n",
    "pickle.dump(feature_list,open('fetaures.pkl','wb')) #Save the list of feature vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad2c2ba5-9243-4634-97b7-31a77dbd6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_img=pickle.load(open(r'images.pkl','rb'))\n",
    "feature_list=(pickle.load(open(r'fetaures.pkl','rb')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9daf6a23-c1ea-4aa2-821b-a43af04f2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3562cea1-cef6-4350-b0d4-50192653d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4bb9b1-60cf-4765-89f2-1ac2f237a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors.fit(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d584e939-63f5-4db1-902e-645ff615cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=6,algorithm='brute',metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a16e0-8096-41b4-9d5a-ec64e6966dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = feature_extraction('16871.jpg', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fa557f1-df6f-4ae1-8851-be3a243f6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance , indices = neighbors.kneighbors([input_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c4803-9249-44e8-a7c2-cb7c6445e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(feature_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5777ba-aa7e-4034-9895-5ac8b4ef8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "871fcd09-f5fd-4b67-9697-5cd555cfcabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4bf532-06bb-4861-acd7-b0aa6366375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('16871.jpg') #uploded Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934faa82-45f5-423b-9206-9d76ff55dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(file_img[indices[0][4]]) #model recommended this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a8a05b-3b0e-4bd4-8b39-87f16e21ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(file_img[indices[0][2]]) #model recommended this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad475ec-bfec-4a4b-ae67-f7fb47be9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(file_img[indices[0][5]]) #model recommended this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbb493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcaff2c-7a41-4e95-b8a7-7f9defd5ca63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b73d614-dde4-4a4e-8322-778fea686291",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90090f10-01e9-4a36-b5d4-36a7f17cee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_img(upload_img):\n",
    "    try:\n",
    "        with open(os.path.join('uploads',upload_img.name),'wb') as f:\n",
    "            f.write(upload_img.getbuffer())\n",
    "        return 1\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d179d970-6053-4537-bcc3-05fa110b543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(path,model):\n",
    "    img=image.load_img(path, target_size=(224,224))# Load image in size of 224,224,3\n",
    "    img_arr=image.img_to_array(img)# storing into array\n",
    "    ex_img_arr=np.expand_dims(img_arr,axis=0)## Expanding the dimension of image\n",
    "    pre_pr_img=preprocess_input(ex_img_arr)## preprocessing the image\n",
    "    result=model.predict(pre_pr_img).flatten()### to make 1d vector\n",
    "    normal_result=result/norm(result)## Normalize the result using norm func from linalg(numpy)\n",
    "    return normal_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9c64a46-260c-48cd-a1f4-06b45beb93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_recom(features, feature_list):\n",
    "    neb=NearestNeighbors(n_neighbors=10,algorithm='brute',metric='euclidean') #using brute force algo here as data is not too big\n",
    "    neb.fit(feature_list)## fit with feature list\n",
    "    dist, ind=neb.kneighbors([features])# return distance and index but we use index to find out nearest images from stored features vector \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "948e8ae2-463d-43ec-b645-e8a180e9b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_img=st.file_uploader('16871.jpg') # To display upload button on screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceec5898-719b-4abf-80f0-c4b26c4d95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Condition to check if image got uploaded then call save_img method to save and preprocess image followed by extract features and recommendation\n",
    "if upload_img is not None:\n",
    "    if Save_img(upload_img):\n",
    "        st.image(Image.open(upload_img))     \n",
    "        st.header(\"file uploaded successfully\")\n",
    "        features=feature_extraction(os.path.join(\"uploads\",upload_img.name),model)\n",
    "        progress_text = \"Hold on! Result will shown below.\"\n",
    "        my_bar = st.progress(0, text=progress_text)\n",
    "        for percent_complete in range(100):\n",
    "            time.sleep(0.02)\n",
    "            my_bar.progress(percent_complete + 1, text=progress_text) ## to add progress bar untill feature got extracted\n",
    "        ind=prod_recom(features, feature_list)# calling recom. func to get 10 recommendation\n",
    "        ### to create 10 section of images into the screen\n",
    "        col1,col2,col3,col4,col5,col6,col7,col8,col9,col10=st.columns(10)\n",
    "        \n",
    "        ##for each section image shown by below code\n",
    "        with col1:\n",
    "            st.image(Image.open(file_img[ind[0][0]]))\n",
    "        with col2:\n",
    "            st.image(Image.open(file_img[ind[0][1]]))\n",
    "        with col3:\n",
    "            st.image(Image.open(file_img[ind[0][2]]))\n",
    "        with col4:\n",
    "            st.image(Image.open(file_img[ind[0][3]]))\n",
    "        with col5:\n",
    "            st.image(Image.open(file_img[ind[0][4]]))\n",
    "        with col6:\n",
    "            st.image(Image.open(file_img[ind[0][5]]))\n",
    "        with col7:\n",
    "            st.image(Image.open(file_img[ind[0][6]]))\n",
    "        with col8:\n",
    "            st.image(Image.open(file_img[ind[0][7]]))\n",
    "        with col9:\n",
    "            st.image(Image.open(file_img[ind[0][8]]))\n",
    "        with col10:\n",
    "            st.image(Image.open(file_img[ind[0][9]]))\n",
    "        # st.text(\"Using Spotify ANNoy\")\n",
    "        # df = pd.DataFrame({'img_id':file_img, 'img_repr': feature_list})\n",
    "        # f=len(df['img_repr'][0])\n",
    "        # ai=AnnoyIndex(f,'angular')        \n",
    "        # for i in tqdm(range(len(feature_list))):\n",
    "        #     v=feature_list[i]\n",
    "        #     ai.add_item(i,v)\n",
    "        # ai.build(10) # no of binary tress want to build more number of tree more accuracy \n",
    "        # neigh=(ai.get_nns_by_item(0,5))\n",
    "        # with col1:\n",
    "        #         st.image(Image.open(file_img[neigh[0]]))\n",
    "        # with col2:\n",
    "        #                 st.image(Image.open(file_img[neigh[1]]))\n",
    "        # with col3:\n",
    "        #                 st.image(Image.open(file_img[neigh[2]]))\n",
    "        # with col4:\n",
    "        #                 st.image(Image.open(file_img[neigh[3]]))\n",
    "\n",
    "        # for i in range(len(neigh)):\n",
    "        #     with st.columns(i):\n",
    "        #         st.image(Image.open(file_img[neigh[i]]))\n",
    "    else:\n",
    "        st.header(\"Some error occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633966cd-48da-41ce-be9f-e8d1a3b045a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Define the category names\n",
    "category_names = [\n",
    "    'Pants', 'Handbags', 'Shirts', 'Shoes', 'Scarves', 'Jewelry', \n",
    "    'Skirts', 'Coats', 'Hats', 'Dresses', 'Shorts', 'Watches', \n",
    "    'Sunglasses', 'Jumpsuits', 'Socks', 'Rings', 'Belts', 'Gloves', \n",
    "    'Swimwear', 'Stockings', 'Neckties'\n",
    "]\n",
    "\n",
    "# Load feature vectors and image paths\n",
    "features = pickle.load(open('fetaures.pkl', 'rb'))  # Numpy array of image features\n",
    "image_paths = pickle.load(open('images.pkl', 'rb'))  # List of corresponding image paths\n",
    "\n",
    "# Ensure the number of categories matches the number of clusters\n",
    "num_categories = len(category_names)\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=num_categories, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(features)  # Assigns each feature to a cluster\n",
    "\n",
    "# Create a dictionary to store images for each cluster\n",
    "categories = {name: [] for name in category_names}\n",
    "\n",
    "# Map cluster labels to category names\n",
    "for img_path, cluster_label in zip(image_paths, cluster_labels):\n",
    "    category_name = category_names[cluster_label]\n",
    "    categories[category_name].append(img_path)\n",
    "\n",
    "# Save the clustered categories to a .pkl file\n",
    "with open('categories.pkl', 'wb') as f:\n",
    "    pickle.dump(categories, f)\n",
    "\n",
    "print(f\"Clustering complete! Saved to categories.pkl.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a04000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
